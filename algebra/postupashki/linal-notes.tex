\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage[dvipsnames]{xcolor}
\usepackage{tcolorbox}
\usepackage{hyperref}

% Всякие кастомные команды
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}

% Поля
\geometry{a4paper, margin=2.5cm}

% Цвета
\definecolor{myblue}{RGB}{44, 62, 80}
\definecolor{mygreen}{RGB}{39, 174, 96}
\definecolor{myred}{RGB}{192, 57, 43}

% Заголовки
\titleformat{\section}{\normalfont\Large\bfseries\color{myblue}}{\thesection}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries\color{mygreen}}{\thesubsection}{1em}{}

% Гиперссылки
\hypersetup{
    colorlinks=true,
    linkcolor=myblue,
    urlcolor=blue!70!black,
    citecolor=blue!70!black
}

% Теоремы и блоки
\tcbuselibrary{breakable, skins}

\tcbset{
    common/.style={
        fonttitle=\bfseries,
        breakable,
        enhanced,
        boxrule=0.5pt,
        arc=3pt,
        coltitle=black,
        top=4pt,
        bottom=4pt,
        left=4pt,
        right=4pt,
        boxsep=4pt,
        before skip=10pt,
        after skip=10pt,
        attach boxed title to top left={xshift=10pt, yshift=-3pt},
        boxed title style={
            colback=white,
            sharp corners,
            boxrule=0pt,
            underlay={\path[fill=#1] (title.south west) rectangle (title.south east);},
        }
    }
}

% Определение
\newtcolorbox{definitionbox}{
    common=blue!30,
    colback=blue!6,
    colframe=blue!80,
    title=Определение
}

% Теорема
\newtcolorbox{theorembox}{
    common=red!30,
    colback=red!6,
    colframe=red!80,
    title=Теорема
}

% Замечание
\newtcolorbox{remarkbox}{
    common=orange!30,
    colback=orange!6,
    colframe=orange!80,
    title=Замечание
}

% Пример
\newtcolorbox{homeworkbox}{
    common=green!30,
    colback=green!6,
    colframe=green!80,
    title=Домашнее задание
}

% Задача
\newtcolorbox{examplebox}{
    common=violet!30,
    colback=violet!6,
    colframe=violet!80,
    title=Пример
}


% Начало документа
\title{\textbf{\Huge Линейная алгебра}\\}
\author{Илья Панов}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

% Привет, добро пожаловать в мой конспект. Если хочешь дополнить его, то пиши, пожалуйста, в моём стиле. Мой конспект поддерживает цветовые блоки:

%\begin{definitionbox}
% Множество называется \textbf{ограниченным}, если существует такое число $M > 0$, что для любого $x \in A$ выполнено $|x| < M$.
%\end{definitionbox}

%\begin{theorembox}
% Если функция $f$ непрерывна на отрезке $[a,b]$ и $f(a)\cdot f(b)<0$, то существует $c \in (a,b)$ такое, что $f(c)=0$.
%\end{theorembox}

%\begin{examplebox}
% Функция $f(x) = x^3 - 2x + 1$ имеет корень на $[0,1]$, так как $f(0)=1$, $f(1)=0$.
%\end{examplebox}

%\begin{itemize}
    % \item $\mathbb{R}$ — множество действительных чисел;
    % \item $\mathbb{N}$ — множество натуральных чисел;
    % \item $\mathbb{Z}$ — множество целых чисел.
%\end{itemize}

% Пример формулы:
%\[
% \int_a^b f(x)\,dx = F(b) - F(a)
%\]

\section{Введение}

Конспект в основном составлялся по \href{https://drive.google.com/drive/folders/1gqBksrkU89tgdOTuxG6GgE3jnozzafNv?usp=sharing}{лекциям} Поступашек для подготовки к поступлению в ШАД и AI Masters. Читать конспект в отрыве от лекций не особо имеет смысл, потому что в лекциях всё сильно подробнее и с рисунками, но в целом можете попробовать: интернет и нейросети творят чудеса. Записи лекций у вас есть (я их пронумеровал, смотрите по порядку), домашки есть в конце каждой секции (курс рекомендует выполнять хотя бы по 10 заданий из дз), учебники и сборники задач - в репозитории.

\section{Аналитическая геометрия}

Сейчас мы начнём с повторения 10-11 класса школы, повыводим всякое для плоскости, потом заметим, что для пространства у нас особо ничего не меняется.\\

\begin{theorembox}
Три вектора (a, b, c) на плоскости всегда линейно зависимы\\

\textbf{Доказательство:}

Можем просто составить систему уравнений, решить её по Гауссу (или как Вам угодно).

\[
\begin{cases}
x \cdot x_a + y \cdot x_b = x_c \\
x \cdot y_a + y \cdot y_b = y_c
\end{cases}
\]

Получим, что решения у нас есть, если вектора не коллинеарны (в конце получим $x_a \cdot y_b \ - x_b \cdot y_a$ в знаменателе, если это выражение равно 0, то это равносильно коллинеарности векторов a и b без ограничения общности). Если какие-то два коллинеарны (а третий не коллинеарен), то колинеарные вектора связаны каким-то коэффициентом k, а третий вектор можем взять с нулевым коэффициентом.
\end{theorembox}

\begin{definitionbox}
    \textbf{Метод Гаусса}, также известный как метод исключения Гаусса, это алгоритм решения систем линейных алгебраических уравнений (СЛАУ) путем последовательного исключения переменных. В основе метода лежит преобразование системы уравнений к равносильной ступенчатой (треугольной) форме (то есть нолики у нас снизу выстраиваются), из которой затем последовательно находятся значения переменных. 
\end{definitionbox}

\begin{theorembox}
Угол между двумя векторами и равносильность определений скалярного произведения\\

\textbf{Доказательство:}

Если есть равносильность определений, то косинус угла выражается очевидно. Равносильность следует из теоремы косинусов: пусть хотим найти угол между векторами a и b, тогда проведем третий - c такой, что он соединяет концы двух других векторов. Пишем теорему косинусов для c, как раз получаем искомый угол и связь определений скалярного.
\end{theorembox}

\begin{theorembox}
\textbf{Неравенство КБШ}: произведение длин векторов не меньше, чем модуль их скалярного произведения: $|a| \cdot |b| \geq |(a, b)|$\\

\textbf{Доказательство:}

Рассмотрим $t \in \R$, теперь возьмем скалярное произведение $(x - ty, x- ty)$, оно $\geq 0$ по свойствам. По линейности раскрываем, получаем квадратный трёхчлен, который $\geq 0$, значит у него $D \geq 0$ - это в точности неравенство КБШ.
\end{theorembox}

\begin{theorembox}
Пусть даны два вектора a и b, отложенные от одной точки, тогда проекция вектора a на вектор b можно найти по формуле $a^` = \frac{(a, b)}{(b, b)} \cdot b$\\

\textbf{Доказательство:}

Что такое проекция, надеюсь, все представляют (просто уронили перпендикуляр). Длина проекция очевидным образом находится из прямоугольного треугольника $|a^`| = |a| \cdot \cos{\phi}$\\

Теперь попробуем выразить сам вектор $a^`$, он лежит на b, тогда чтобы получить вектор проекции, мы хотим использовать направление вектора b (единичный вектор) и умножить получившийся вектор на длину проекции: $a^` = \frac{b}{|b|} \cdot |a^`|$. Подставляем $|a^`|$, $\cos{\phi}$ заменяем на $\frac{(a, b)}{|a| \cdot |b|}$, получили требуемое.

\end{theorembox}

\begin{theorembox}
Точка $(x, y)$ принадлежит прямой $l$ (прямая задана точкой $(x_0, y_0)$ и направляющим вектором $(\alpha, \beta)$) тогда и только тогда, когда $\frac{x - x_0}{\alpha} = \frac{y - y_0}{\beta}$. Это равенство мы будем называть каноническим уравнением прямой. В эту же теорему включим вывод других способов задать прямую\\

\textbf{Доказательство:}

Очев: если у нас точка $(x, y)$ лежит на прямой, тогда у нас вектора $(x - x_0, y - y_0)$ и $(\alpha, \beta)$ колинеарны, тогда $\exists \ k \in \R \ | \ (x - x_0, y - y_0) = k \cdot (\alpha, \beta)$. Рассмотрев это равенство покоординатно, получим требуемое отношение. В обратную сторону аналогично, просто введём $k$, скажем про коллинеарность, дальше принадлежность точки прямой очевидна.\\

Из получившегося уравнения очевным образом получаем параметрическое уравнение прямой:

\[
\begin{cases}
x = x_0 + t \cdot \alpha \\
y = y_0 + t \cdot \beta
\end{cases}
\]

По сути заменили k на t. Далее получим общее уравнение прямой $Ax + By +C = 0$. Просто возьмём каноническое и крест-накрест перемножим. Получим $\beta x - \alpha y - x_o \beta + y_0 \alpha = 0$. Дальше мы просто занимаемся переобозначением.
\end{theorembox}

\begin{remarkbox}
    Также заметим, что вектор с координатами $(A, B)$ (читать как $(\beta, -\alpha)$) - это нормаль-вектор нашей прямой. Проверяется через скалярное произведение (помним, что $(\alpha, \beta)$ - это направляющий вектор нашей прямой).
\end{remarkbox}

\begin{theorembox}
Прямая $l: Ax +By + C = 0$ разбивает плоскость на 2 полуплоскости. Если мы возьмём какие-то 2 точки $I_1, I_2$ из разных полуплоскостей, тогда $l(I_1) \cdot l(I_2) < 0$\\

\textbf{Доказательство:}

Зафиксируем точку $(x_0, y_0) \in l$. Теперь рассмотрим скалярное произведение нормаль-вектора и $(x_1 - x_0, y_1 - y_0)$ (если считать, что у точки $I_1$ координаты $(x_1, y_1)$). Аналогично для второй точки $I_2$. Тогда одно скалярное произведение будет $>0$, а другое $<0$ в силу свойства скалярного (если точнее, то просто пользуемся, что косинус тупого угла отрицательный).\\
Например, подробнее для точки $I_1$ из верхней полуплоскости (БОО): $A(x_1 - x_0) + B(y_1 - y_0) > 0$, раскроем скобки, обозначим $C = -Ax_0 - By_0$. Потом мы всё это перемножим с выражением для второй точки: $Ax_2 + Bx_2 + C < 0$. Получим то, что и хотели: $l(I_1) \cdot l(I_2) < 0$.

\end{theorembox}

\begin{theorembox}
Формула расстояния от точки $(x_0, y_0)$ до прямой $l: Ax + By + C = 0$ - это $d(x_0, y_0) = \frac{|Ax_0 + By_0 + C|}{\sqrt{A^2 + B^2}}$\\

\textbf{Доказательство:}

Рассмотрим точку $(x, y) \in l$. Теперь построим вектор $(x_0 - x, y_0 - y)$, спроецируем его на нормаль вектор (точнее мы хотим посмотреть на длину проекции): $|(A, B)| \cdot |\frac{A(x_0 - x) + B(y_0 - y)}{A^2 + B^2}|$. $|(A, B)|$ - это внезапно $\sqrt{A^2 + B^2}$. Сокращаем, вводим обозначение C, получаем требуемое.
\end{theorembox}

\begin{remarkbox}
Обсудим взаимное расположение прямых: совпадают, параллельны или пересекаются. В терминах коэффициентов это соответственно $\frac{A_1}{A_2} = \frac{B_1}{B_2} = \frac{C_1}{C_2}$, $\frac{A_1}{A_2} = \frac{B_1}{B_2}$ или никакое из предыдущих равенств не выполняется.\\

В терминах матриц совпадение это:

\[
rk \begin{pmatrix}
A_1 & B_1\\
A_2 & B_2
\end{pmatrix}
 = 1\]

\[
rk \begin{pmatrix}
A_1 & B_1 & C_1\\
A_2 & B_2 & C_2
\end{pmatrix}
 = 1\]

Аналогично для параллельности у нас ранг большой матрицы будет 2, а в случае пересечения у нас ранг и маленькой, и большой матрицы будет 2.

\end{remarkbox}

\begin{definitionbox}
    \textbf{Ранг матрицы (rk)} - это максимальный порядок минора матрицы, отличный от нуля. Иными словами, это число, равное максимальному количеству линейно независимых строк (или столбцов) в матрице. Ранг матрицы показывает размерность подпространства, натянутого на строки (или столбцы) матрицы.
\end{definitionbox}

\begin{theorembox}
Площадь параллелограмма, построенного на векторах $(a, c)$ и $(b, d)$ - это определитель:
\[
\begin{vmatrix}
a & c\\
b & d
\end{vmatrix}
\]

\textbf{Доказательство:}

$S = |a| \cdot |b| \cdot \sin{\phi}$. Меняем синус на косинус по ОТТ, заносим всё под корень, раскрываем скобки, там у нас получается полный квадрат: $\sqrt{(ad - bc)^2}$, а это в точности определитель.
\end{theorembox}

\begin{remarkbox}
Из такого геометрического смысла определителя становятся очевидны всякие свойства про линейность по строке, иммутабельность при транспонировании.\\

Такую же формулу, кстати, можно вывести для $\R^3$, но это будет просто более глиномесно:

\[
V = 
\begin{vmatrix}
c_1 & c_2 & c_3\\
a_1 & a_2 & a_3\\
b_1 & b_2 & b_3
\end{vmatrix}
\]
\end{remarkbox}

Вот теперь мы плавно перешли к пространствам. Будем волшебным образом перетаскивать формулы из плоскости, натягивать их на пространство, также будем что-то новое вводить.\\

\begin{remarkbox}
Каноническое уравнение прямой в $\R^3$ - это $\frac{x - x_0}{\alpha} = \frac{y - y_0}{\beta} = \frac{z - z_0}{\gamma}$.\\\\

Уравнение плоскости можно построить по трём точкам, зафиксируем первую точку, от неё проведём 2 вектора к двум оставшимся, теперь возьмём какую-то точку $(x, y, z)$, вектор от первой точки к новой должен быть ЛНЗ. Получили 3 вектора, которые образовали плоскость. Объём, натянутый на эти 3 вектора, равен 0, тогда мы просто пишем объём через определитель, раскрываем, получаем: $Ax + By +Cz +D = 0$.\\

Давайте до кучи напишем параметрическое уравнение плоскости:
\[
\begin{pmatrix}
x \\
y \\
z
\end{pmatrix}
=
\begin{pmatrix}
x_0 \\
y_0 \\
z_0
\end{pmatrix}
+
\lambda
\begin{pmatrix}
u_1 \\
u_2 \\
u_3
\end{pmatrix}
+
\mu
\begin{pmatrix}
v_1 \\
v_2 \\
v_3
\end{pmatrix}
\]

где u и v - базисные векторы плоскости, а $(x_0, y_0, z_0)$ - какая-то начальная точка.
\end{remarkbox}

\begin{theorembox}
Формула перехода к новому базису.\\

\textbf{Доказательство:}

Рассмотрим вектор $(x, y)$ в базисе $\{e_1, e_2\}$. Тогда наш вектор $a = xe_1 + ye_2$, а в другом базисе наш вектор - это $a = x^`e^`_1 + y^`e^`_2$. Хотим узнать $(x^`_1, y^`_2)$. $e^`_1 = a_{11}e_1 + a_{21}e_2$ и $e^`_2 = a_{12}e_1 + a_{22}e_2$. Подставим и преобразуем, потом воспользуемся единственностью представления вектора в данном базисе, тогда $x = x^`a_{11} + y^`a_{12}$, аналогично для y.
\end{theorembox}

\begin{remarkbox}
Вопрос исследования взаимного расположения прямой и плоскости, плоскости и плоскости довольно тривиальный, просто пользуемся параметрическим уравнением плоскости и прямой, а дальше очев: сводим задачу к исследованию расположения направляющего вектора прямой и нормаль-вектора плоскости и тд и тп, просто системы уравнений.
\end{remarkbox}

\begin{definitionbox}
\textbf{Угол между прямой и плоскостью} - это угол между прямой и проекцией прямой на данную плоскость.
\end{definitionbox}

\begin{theorembox}
Формула расстояния от точки $(x_0, y_0, z_0)$ до плоскости $\alpha: Ax + By + Cz + D = 0$ - это $d(x_0, y_0, z_0) = \frac{|Ax_0 + By_0 + Cz_0 + D)|}{\sqrt{A^2 + B^2 + C^2}}$\\

\textbf{Доказательство:}

Выводится также, как и для двумерного случая.
\end{theorembox}

\begin{remarkbox}
Расстояние между плоскостями или прямыми, или прямыми и плоскостями - это длина общего перпендикуляра. Задача сводится к расстоянию от точки до плоскости/прямой.
\end{remarkbox}

\begin{homeworkbox}
    Из Смирнова (\texttt{smirnov.pdf}) решайте все задачи из 3.1-3.4, 4.1-4.4 и 474-482. Не обяз решать всё, решайте пока не почувствуете, что прониклись. Задачи халява, все идеи есть в лекциях.
\end{homeworkbox}

\section{Векторные пространства и матрицы}

\begin{definitionbox}
    Пусть у нас есть векторное пространство размерности n, тогда набор векторов $\{e_1, \dots, e_n\}$ будет называться \textbf{базисом} этого пространства, если они все линейно независимы: $\sum \lambda_i \cdot e_i = 0 \Rightarrow \lambda_i = 0$.
\end{definitionbox}

\begin{theorembox}
У любого конечномерного векторного пространства сущестувет базис.\\

\textbf{Доказательство:}

Просто предъявляем алгоритм. Возьмём $e_1 = v_1 \neq 0$, потом возьмём $e_2 = v_2 \in V$ такой, что $\lambda_1 \cdot e_1 + \lambda_2 \cdot e_2 = 0 \Rightarrow \lambda_1 = 0, \lambda_2 = 0$. Если такой не нашёлся, тогда у нас базис из 1 вектора, имеем просто одномернопространство. Потом возьмём $e_3 = v_3 \in V \ \dots$ и тд. 
\end{theorembox}

\begin{remarkbox}
Система векторов обладает единственным базисом только в случае 0-мерного пространства.
\end{remarkbox}

\begin{definitionbox}
    Векторное пространство W представимо в виде \textbf{прямой суммы} пространств U и V, если $\forall w \in W \ \exists u \in U \ \& \ \exists v \in V \ | \ w = u + v$. Очень важно, что U и V пересекаются только по нулевому вектору.
\end{definitionbox}

\begin{theorembox}
a) Размерность подпространства не превосходит размерности пространства.\\
б) W - векторное пространство, U - его подпространство, тогда $\exists V$ такое, что $W = U + V$.\\

\textbf{Доказательство:}

а) очевидно, пытливый читатеть может самостоятельно привести доказательство этого пункта.\\
б) Выбираем базис в U, потом дополняем его до всего базиса W, тогда $\forall w \in W \ w = \sum_{i = 1}^{k} w_i \cdot e_i + \sum_{i = k + 1}^{n} w_i \cdot e_i$, где $k = dimU, n = dimV$. Тогда первая сумма у нас лежит в U, а вот то, что осталось мы определим как V, тогда базис нового пространства - это просто те, вектора, которыми мы дополнили базис U до базиса W. 
\end{theorembox}

\begin{remarkbox}
Если V - в.п. ($dimV = n$) над полем из q элементов, тогда всего векторов у нас $q^n$ (потому что $v = \sum q_i \cdot v_i$), а способов выбрать базис - $(q^n - 1)(q^n - q)\dots(q^n - q^{n - 1})$ (первым берём любой \textbf{ненулевой} вектор, потом берем вектор, который ЛНЗ с первым, то есть $e_2 \neq \lambda_1\cdot e_1$, на место лямбды q вариантов и тд).
\end{remarkbox}

\begin{theorembox}
Ранг матрицы $A|B$ (\textit{это приписывание матрицы B справа от матрицы A}) не превосходит суммы рангов матриц A и B.\\

\textbf{Доказательство:}

$A|B = A|0 + 0|B$, тогда $rk(A|B) = rk((A|0) + (0|B)) \leq rk(A|0) + rk(0|B) = rk(A) + rk(B)$.
\end{theorembox}

\begin{theorembox}
Всякую матрицу ранга r можно представить в виде суммы r матриц ранга 1, но нельзя представить в виде суммы меньшего числа таких матриц.\\

\textbf{Доказательство:}

$rkA = r, A = \sum A^`_i$. Без ограничения общности будем считать, что у нас ЛНЗ первые r строчек матрицы:

\[
\begin{pmatrix}
A_1 \\
A_2 \\
\dots \\
A_r\\
A_{r + 1}\\
\dots\\
A_n
\end{pmatrix}
=
\begin{pmatrix}
A_1 \\
0 \\
\dots \\
0\\
\lambda_1^{r+1} A_1\\
\lambda_1^{r+2} A_1\\
\dots
\end{pmatrix}
+
\begin{pmatrix}
0 \\
A_2 \\
\dots \\
0\\
\lambda_2^{r+1} A_2\\
\lambda_2^{r+2} A_2\\
\dots
\end{pmatrix}
+
\dots
\]

$rkA = rk(\sum A_k) \leq \sum rk(A_k) = k$, если k < r, тогда $rkA < r$ - противоречие.
\end{theorembox}

\begin{theorembox}
$A^T A = A A^T \Rightarrow (A^{-1})^T = A^{-1}$.\\

\textbf{Доказательство:}

$A^{-1}A = E$, транспонируем $(A^{-1}A)^T = E^T \Leftrightarrow A^T (A^{-1})^T = E^T$, домножим слева на $A^{-1}$, получим $(A^{-1})^T = A^{-1}$
\end{theorembox}

Далее в лекции разобраны несколько опорных задач, связанных с коммутативностью и обратимостью матрицы. Доказательства как правило проводились через \textbf{след матрицы}, потому что работать с числами куда приятнее и понятнее, чем с матрицами. Не считаю нужным конспетировать эти задачи. Может быть кто-то захочет продолжить моё дело и откроет пул реквест.

\begin{definitionbox}
    \textbf{Следом квадратной матрицы} A (dimA = n) мы будем называть $tr(A) = \sum_{i = 1}^n a_{ii}$.\\

    \textbf{След} становится удобным инструментом в доказательстве теорем про матрицы благодаря ряду свойств:
    \begin{enumerate}
        \item $tr(\alpha A + \beta B) = \alpha \cdot tr(A) + \beta \cdot tr(B)$
        \item $tr(C^{-1}AC) = tr(A)$, в частности $tr(AB) = tr(BA)$
        \item $tr(A) = tr(A^T)$
        \item \textbf{След матрицы} равен сумме её собственных значений.
    \end{enumerate}
\end{definitionbox}

\begin{remarkbox}
    Строковый и столбцовый ранг совпадают.
\end{remarkbox}

\begin{definitionbox}
    Симметрические матрицы: $A = A^T$, кососимметрические матрицы: $A^T = -A$. Также заметим, что в последнем случае у нас обязательно на диагонали должны быть нули, т.к. $a_{ii} = -a_{ii} \Leftrightarrow a_{ii} = 0$, а остальные элементы $a_{ij} = -a_{ji}$.
\end{definitionbox}

\begin{remarkbox}
    Рассмотрми пространства симметрических матриц (U) и кососимметрических матриц (V). Размерность первого пространства - это $\frac{n^2 + n}{2}$ (потому что такая матрицы задаётся с помощью n чисел на диагонали + количество чисел над диагональю, для этого нужно из всех чисел матрицы вычесть диагональ и поделить пополам - $\frac{n^2 - n}{2}$. Размерность второго пространства тогда - это $\frac{n^2 - n}{2}$ (раз на диагонали только нули).\\

    Теперь сложим эти размерности $\frac{n^2 + n}{2} + \frac{n^2 - n}{2} = \frac{2n^2}{2} = n^2$. Получили размерность всего пространства квадратных матриц $M_n(\R)$. Также заметим, что пространства симметрических и кососимметрических матриц пересекаются только по нулевой матрице (то есть $A = - A$). Тогда $A \in M_n(\R) \ \Rightarrow \ \exists U, V \ A = U \oplus V$ причём U - симметрическая матрица, а V - кососимметрическая матрица.
\end{remarkbox}

\begin{theorembox}
    $rk(A + B) \leq rk(A) + rk(B)$\\

    \textbf{Доказательство:}

    Идейно: $rk(A+B) = rk(A) +rk(B) - rk(A\cap B) \leq rk(A) + rk(B)$
\end{theorembox}

\begin{remarkbox}
    $tr(AB) = tr(BA)$, но $rk(AB) \neq rk(BA)$
\end{remarkbox}

\begin{definitionbox}
    $\R_n[x]$ - пространство многочленов, базисом которого может быть, например, $\{1, x, x^2,\dots, x^n\}$.\\

    Скалярное произведение двух функций $f$ и $g$ - это $(f, g) = \int_a^b f(x)g(x)dx$.
\end{definitionbox}

\begin{remarkbox}
    А скалярное произведение матриц - это tr их произведения. Можете прогнать по свойствам скалярного произведения и убедиться в этом.
\end{remarkbox}

\begin{theorembox}
    Рассмотрим набор векторов $\{e_1, e_2, \dots,e_n\}$ со следующим свойством:
    \[
        \begin{cases}
        (e_i, e_i) = 1\\
        (e_i, e_j) = 0
        \end{cases}
    \]
    Докажем, что этот набор векторов является базисом.\\

    \textbf{Доказательство:}

    Проверим ЛНЗ. Хотим $\sum \lambda_i e_i = 0 \Rightarrow \forall i \ \lambda_i = 0$. Рассмотрим скалярное произведение $\forall i \ (e_i, \sum \lambda_i e_i) =0 $, раскроем по свойству линейности, получим что-то такое: $\sum \lambda_j (e_i, e_j) = \lambda_i (e_i, e_i) = 0 \Rightarrow \lambda_i = 0$.
    
\end{theorembox}

\begin{definitionbox}
    Набор векторов из теоремы выше называется \textbf{ортонормированным базисом}.
\end{definitionbox}

\begin{definitionbox}
    $W^\perp := \{w^\perp \in W^\perp \ | \ \forall w \in W \ (w^\perp, w) = 0\}$
\end{definitionbox}

\begin{remarkbox}
    $V = W \oplus W^\perp$. Очевидно, что $W$ и $W^\perp$ пересекаются только по нулю, если бы мы нашли какой-то $x \in W, W^\perp$, то получили бы что-то в духе $(x, x) = 0$, а отсюда по свойству скалярного произведения получаем, что $x = 0$.
\end{remarkbox}

\begin{theorembox}
    \textbf{Метод Грама–Шмидта}: Любой базис $ \{e_1, ..., e_n\} $ евклидова пространства можно преобразовать в ортонормированный базис $ \{f_1, ..., f_n\} $ следующим образом:

    \begin{align*}
    u_1 &= e_1, \\
    u_2 &= e_2 - \frac{(e_2, u_1)}{(u_1, u_1)} u_1, \\
    u_3 &= e_3 - \frac{(e_3, u_1)}{(u_1, u_1)} u_1 - \frac{(e_3, u_2)}{(u_2, u_2)} u_2, \\
    &\vdots \\
    f_i &= \frac{u_i}{\|u_i\|}.
    \end{align*}
\end{theorembox}

\begin{theorembox}
    Пусть A - матрица размера $n \times n$. Если для любой матрицы $X$ размера $n \times n$ справедливо равенство $tr(AX) = 0$, то $A = 0$.\\

    \textbf{Доказательство:}

    Попробуем $X = A^T$. $tr(AA^T) = \sum a_{ij}^2 = 0 \ \Rightarrow \ \forall i, j \ a_{ij} = 0$. Либо можно сказать, что у нас $tr(AX)$ - это скалярное произведение на пространстве матриц, причём у нас $\forall X \ tr(AX) = 0$, то есть A перпендикулярно любому вектору, а это возможно в том случае, если A - это нулевой вектор.
\end{theorembox}

\begin{homeworkbox}
    Домашка есть в \texttt{2-vector-spaces-102.pdf}
\end{homeworkbox}

\section{Линейные операторы}

\begin{definitionbox}
    Отображение $f: V \rightarrow V$ мы будем называть \textbf{линейным}, если оно удовлетворяет следующим свойствам:
    \begin{enumerate}
        \item $f(u + v) = f(u) + f(v)$
        \item $f(\lambda v) = \lambda f(v)$
    \end{enumerate}
\end{definitionbox}

\begin{remarkbox}
    Если отображение задаётся матрицей, то оно линейно. \\
    Стобцы в матрице линейного отображения - это образы базисных векторов.
\end{remarkbox}

\begin{definitionbox}
    \textbf{Движением} мы будем называть отображение $f: \R^2 \rightarrow \R^2$, которое сохраняет расстояние между образами: $d(x, y) = d(f(x), f(y))$.
\end{definitionbox}

\begin{theorembox}
    Движение - это биекция и у него всегда есть обратное отображение-движение.\\

    \textbf{Доказательство:}

    Пусть у нас есть две точки $x_1, x_2$ (различные), они не могут перейти в какую-то одну точку $f(x_1) = f(x_2)$, иначе у нас нарушится свойство движения: $d(x_1, x_2) \neq d(f(x_1), f(x_2)) = 0$.
\end{theorembox}

\begin{theorembox}
    Движение сохраняет углы.\\

    \textbf{Доказательство:}

    Рассмотрим треугольник. Он перейдёт в какой-то другой треугольник, причём равный изначальному по трём сторонам. Раз треугольники равны, то равны и углы.
\end{theorembox}

\begin{theorembox}
    \textbf{Теорема Шаля}: Идейно - всякое движение есть поворот, симметрия или композиция симметрий и поворотов.\\

    \textbf{Доказательство:}

    Начнём с частного случая теоремы, разберем движения, которые сохраняют точку $(0, 0)$. Рассмотрим куда у нас перейдут базисные вектора $(e_1, e_2)$. По сути мы хотим получить матрицу:
    \[
        \begin{pmatrix}
            f(e_1) & f(e_2)
        \end{pmatrix}
    \]

    Пусть у нас угол между $e_1$ и $f(e_1)$ будет равен $\phi$. Тогда:

    \[
        f(e_1) \rightarrow
        \begin{pmatrix}
            \cos{\phi}\\
            \sin{\phi}
        \end{pmatrix}
    \]

    Аналогично для вектора $e_2$. Заметим, что раз $e_1 \perp e_2$, то $f(e_1) \perp f(e_2)$, поэтому угол между $f(e_2)$ и $e_2$ также выражается через $\phi$. С учётом ориентации получаем:

    \[
        f(e_2) \rightarrow
        \begin{pmatrix}
            -\sin{\phi}\\
            \cos{\phi}
        \end{pmatrix}
    \]

    По итогу просто имеем \textbf{матрицу поворота} :)

    \[
        \begin{pmatrix}
            \cos{\phi} & -\sin{\phi}\\
            \sin{\phi} & \cos{\phi}
        \end{pmatrix}
    \]

    НО! У нас ведь $f(e_2)$ мог "смотреть" в противоположную сторону, тогда матрица для $f(e_1)$ остаётся такой же, а вот вторая немного меняется, имеем внезапно \textbf{матрицу симметрии}:

    \[
        \begin{pmatrix}
            \cos{\phi} & \sin{\phi}\\
            \sin{\phi} & -\cos{\phi}
        \end{pmatrix}
    \]

    Если какое-то отображение не сохраняет точку ноль, то нам ничто не мешает начать откладывать базисные вектора относительно $f(0)$, таким образом, все движения, которые сохраняют 0 выражаются примерно так: $f(x) = Ax + \binom{x_0}{y_0}$, где $\binom{x_0}{y_0}$ - это координаты точки $f(0)$.
\end{theorembox}

\begin{definitionbox}
    \textbf{Обратным отображением} в терминах матриц мы будем называть такое отображение $A^{-1}$, что $A \circ A^{-1} =  A^{-1} \circ A = E$.
\end{definitionbox}

\begin{theorembox}
    Матрица обратима, если ее определитель отличен от нуля.\\

    \textbf{Доказательство:}

    Можем переформулировать $\exists A^{-1} \ \Leftrightarrow \ \{f(e_1), f(e_2)\} - \text{тоже базис}$. Тогда из этого следует, что у нас есть обратное отображение. Почему? См. доказательство про обратимость движения. Также берём различные вектора u и v, а потом внезапно получаем $f(u) = f(v)$, тогда $u_1f(e_1) + u_2f(e_2) = v_1f(e_1) + v_2f(e_2) \Rightarrow (u_1 - v_1)f(e_1) + (u_2 - v_2)f(e_2) \Rightarrow u_1 - v_1 = u_2 - v_2 = 0$ - противоречие с различностью u и v. Стрелочка влево доказана.\\

    Теперь в другую сторону. От противного, $f(e_1), f(e_2)$ не образуют базис. Тогда $\lambda_1 f(e_1) + \lambda_2 f(e_2) = 0$, причём коэффициенты не равны 0. По линейности такжем имеем $f(\lambda_1 e_1 + \lambda_2 e_2) = 0$, но $f(0) = 0$. То есть какие-то 2 различных вектора перешли в один. Противоречие.\\

    Таким образом у нас есть обратная матрица тогда и только тогда, когда вектора $f(e_1), f(e_2)$ не коллинеарны, а это значит, что определитель не равен 0.
\end{theorembox}

\begin{remarkbox}
    У нас определитель равен 0 может быть, если он состоит из линейно зависимых векторов. Разберём на примере $2 \times 2$:

    \[
        \begin{vmatrix}
        a & c\\
        b & d
        \end{vmatrix} = ad - cb = 0 \Rightarrow \frac{a}{b} = \frac{c}{d} = k
    \]

    Получили условие коллинеарности. Этим свойством определителя мы и пользуемся в теореме выше.
\end{remarkbox}

\begin{remarkbox}
    Алгоритм поиска обратной матриц довольно прост, если хотим найти $A^{-1}$, тогда рассмотрим матрицу $A|E$ и с помощью элементарных преобразований пытаемся превратить нашу матрицу в $E|X$, тогда $X = A^{-1}$.
\end{remarkbox}

\begin{remarkbox}
    $(AB)^{-1} = B^{-1}A^{-1}$
\end{remarkbox}

\begin{theorembox}
    $det(AB) = detA \cdot detB$\\

    \textbf{Доказательство:}

    С геометрической точки зрения определитель - это просто площадь параллелограмма, натянутого на базисные вектора. $C = AB$ - это же просто композиция. Сначала B как-то растянул нашу площадь, потом A. Соответственно $detA \cdot detB$ - это то же самое, сначала мы растягиваемся в A раз, потом в B раз.

\end{theorembox}

\begin{remarkbox}
    Замена базиса линейного отображения. Пусть у нас есть $f: V \rightarrow W$, $x = C_1x^`, y = C_2y^`$, $y = A_fx$, где $C_1, C_2$ - матрицы замены координат, после подстановки получим $y^` = C_2^{-1} A_f C_1 x^`$.
\end{remarkbox}

\begin{definitionbox}
    Пусть дано $f: V \rightarrow W$, тогда $Kerf = \{v \in V \ | \ f(v) = 0\}$ называется \textbf{ядром} $f$, а $Imf =  \{w \in W \ | \ \exists v \in V \ f(v) = w\}$ называется \textbf{образом} $f$.
\end{definitionbox}

\begin{remarkbox}
    $rk(A_f) = dim(Imf)$\\

    Полезное замечание, выводится оно из $dim(\langle f(e_1), f(e_2), \dots, f(e_n) \rangle)$ - линейная оболочка, состоящая из образов базисных векторов. Теперь получим ещё более интересные свойства:

    \begin{enumerate}
        \item $rkAB \leq rk A$ и $rkAB \leq rk B$, в частности $rk(C^{-1}AC) = rkA$
        \item $rk(A + B) \leq rkA + rkB$
    \end{enumerate}
\end{remarkbox}

\begin{definitionbox}
    Диагональной матрицей мы будем называть матрицы вида:

    \[
        \begin{pmatrix}
            \lambda_1 &0 & 0 & \dots & 0 \\
            0 & \lambda_2 & 0 & \dots & 0 \\
            & &\dots \\
            0 & 0 & 0 & 0 & \lambda_n
        \end{pmatrix}
    \]
\end{definitionbox}

\begin{definitionbox}
    Хотим научиться преобразовывать нашу матрицу к диагональному виду. Помним, что столбцы у нас - это образы базисных векторов, тогда имеем:

    \[
        \begin{cases}
            f(e_1) = \lambda_1 e_1 \\
            f(e_2) = \lambda_2 e_2 \\
            \dots \\ 
            f(e_n) = \lambda_n e_n
        \end{cases}
    \]

    В общем виде хотим научиться такие $\lambda$ и v такие, что $Av = \lambda v$. Такие числа $\lambda$ мы будем называть \textbf{собственными числами}, а вектора v - \textbf{собственными векторами}.\\

    $Av = \lambda v \Leftrightarrow Av = \lambda Ev \Leftrightarrow (A - \lambda E)v = 0$, также будем считать, что $v \neq 0$, иначе уж совсем неинтересно. Тогда у нас v принадлежит ядру, а значит матрица у нас вырожденная, то есть $det(A - \lambda E) = 0$.

    Полученное уравнение мы будем называть \textbf{характеристическим многочленом}. Решаем его, получаем $\lambda$ (возможно несколько), подставляем их в исходное, решаем уравнение на v. Теперь мы имеем и новый базис (матрица перехода по сути), и диагональный вид.
\end{definitionbox}

\begin{remarkbox}
    Если существует ненулевой вектор v, такой что $(A - \lambda E)v = 0$, то это означает, что у матрицы $A - \lambda E)$ есть ненулевое решение однородной системы, то есть её ядро непусто, а раз у матрицы ненулевое ядро, то она не обратима, то есть вырождена.
\end{remarkbox}

\begin{theorembox}
    Теорема о ядре и образе: $dimkerA + dimImA = dimA$
\end{theorembox}

\begin{remarkbox}
    Матрица диагонализуема, если существует базис из собственных векторов.
\end{remarkbox}

\section{Определители}

Чтобы разобраться с темой определители, надо сначала познакомиться с перестановками, потом поймёте почему. Сейчас ВЫ НЕ ГОТОВЫ.\\

\begin{definitionbox}
    \textbf{Перестановкой} называется биективное отображение множества первых \( n \) натуральных чисел на себя. Формально:


    \textbf{Перестановкой} степени \( n \) называется любая биекция:
    \[
    \sigma \colon \{1, 2, \dots, n\} \to \{1, 2, \dots, n\}.
    \]
    Множество всех перестановок степени \( n \) обозначается \( S_n \) и называется \textit{симметрической группой} степени \( n \).
\end{definitionbox}

Перестановки, на мой взгляд, - довольно непростая тема, потому что легко запутаться, поэтому давайте разберём примеры, поймём как это вообще всё работает: что и куда переходит.\\

\begin{examplebox}
    Матричная запись перестановки и как мы можем сократить запись с помощью \textbf{циклических перестановок}

    \[
        \sigma = \begin{pmatrix}
        1 & 2 & 3 & 4 \\
        3 & 4 & 1 & 2
        \end{pmatrix}
         = (1\;3)(2\;4)
    \]

    Вот эта сокращённая запись означает \textbf{цикл}, $(1\;3)$ - это 1 перешла в 3, а 3 перешла в 1, цикл закончился, потом мы описываем второй цикл. Если элемент статичен (никуда не переходит), мы считаем, что он переходит в себя.
\end{examplebox}

\begin{examplebox}
    Умножение перестановок выполняется справа налево (как композиция функций).
    
    \[
        \tau = (1\;3\;5)(2\;4\;6\;7), \quad \sigma = (1\;4\;7)(2\;3\;5\;6)
    \]
    
    Вычисляем $\tau \circ \sigma$:
    \begin{enumerate}
        \item Для элемента 1: $\sigma(1)=4$, $\tau(4)=6$ $\Rightarrow$ $1\to6$
        \item Для элемента 2: $\sigma(2)=3$, $\tau(3)=5$ $\Rightarrow$ $2\to5$
        \item Для элемента 3: $\sigma(3)=5$, $\tau(5)=1$ $\Rightarrow$ $3\to1$
        \item Для элемента 4: $\sigma(4)=7$, $\tau(7)=2$ $\Rightarrow$ $4\to2$
        \item Для элемента 5: $\sigma(5)=6$, $\tau(6)=7$ $\Rightarrow$ $5\to7$
        \item Для элемента 6: $\sigma(6)=2$, $\tau(2)=4$ $\Rightarrow$ $6\to4$
        \item Для элемента 7: $\sigma(7)=1$, $\tau(1)=3$ $\Rightarrow$ $7\to3$
    \end{enumerate}
    
    Результат:
    \[
        \tau \circ \sigma = (1\;6\;4\;2\;5\;7\;3)
    \]
\end{examplebox}

\begin{definitionbox}
    \textbf{Транспозиция} - это перестановка длины 2: $(i_1\;i_2)$ 
\end{definitionbox}

\begin{theorembox}
    Любую перестановку можно представить как произведение транспозиций.
\end{theorembox}

\begin{definitionbox}
    \textbf{Знак перестановки} можно задать так:\\
    $sgn(i_1\ i_2) = -1$\\
    $sgn(\tau \ \sigma) = sgn(\tau) \cdot sgn(\sigma)$
\end{definitionbox}

\begin{remarkbox}
    Знак \textbf{цикла} - это число транспозиций, в которое он раскладывается. Имеется в виду $(-1)^k$, где k - число транспозиций.
\end{remarkbox}

Вот теперь, маслята, вы готовы к детерминанту.

\begin{definitionbox}
    \textbf{Определитель (или детерминант)} - это:

    \[
        det \begin{pmatrix}
            a_{11} & a_{12} & \dots &a_{1n}\\
            &\dots & \dots \\
            a_{n1} & a_{n2} & \dots & a_{nn}
        \end{pmatrix} = \sum_{\sigma \in S_n} sgn(\sigma) a_{1p_1} a_{2p_2} \dots a_{np_n}
    \]
    \[ \text{На всякий случай уточню, что }
    \sigma = \begin{pmatrix}
        1 & 2 & 3 & \dots & n\\
        p_1 & p_2 & p_3 & \dots & p_n
    \end{pmatrix}
    \]
\end{definitionbox}

Страшно? Видимо не были готовы, давайте разберём пример, чтобы стало хоть немного потятнее, и эта формула выглядела осмысленнее. Возьмём матрицу $2\times 2$:

\begin{examplebox}
    Заметьте, что первый индекс - это у нас строки, а второй индекс - это столбец, перестановки именно по столбцу! Запись $a_{1p_1}$ означает, что 1 переходит в $p_1$. $e$ - это тождественная перестановка, которая оставляет всё на своих местах.

    \[
    det\begin{pmatrix}
        a_{11} & a_{12} \\
        a_{21} & a_{22}
    \end{pmatrix} = sgn(e) \cdot a_{11} a_{22} + sgn(1\;2) \cdot a_{12} a_{21}
    \]

    $\sigma \in S_2 = \{e, (1\;2)\}$, потому что $n = 2$, $S_1$ нет смысла рассматривать.
\end{examplebox}

\begin{theorembox}
    \textbf{Свойства определителя:}
    \begin{enumerate}
        \item Определитель линеен по строкам
        \item $det(A) = det(A^T)$
        \item Определитель кососимметричен
        \item Если у нас есть линейно зависимые строки, то определитель равен нулю
    \end{enumerate}

    \textbf{Доказательство:}
    \begin{enumerate}
        \item \[
                    \begin{vmatrix}
                        A_1 + B_1 \\
                        A_2\\
                        \dots\\
                        A_n
                    \end{vmatrix}
                    =
                    \begin{vmatrix}
                        A_1\\
                        A_2\\
                        \dots\\
                        A_n
                    \end{vmatrix}
                    +
                    \begin{vmatrix}
                        B_1 \\
                        A_2\\
                        \dots\\
                        A_n
                    \end{vmatrix}
              \]
        
            Просто пользуемся дистрибутивностью: $\sum_{\sigma \in S_n} sgn(\sigma) (a_{1p_1} + b_{1p_1}) a_{2p_2} \dots a_{np_n} = \sum_{\sigma \in S_n} sgn(\sigma) a_{1p_1} a_{2p_2} \dots a_{np_n} + \sum_{\sigma \in S_n} sgn(\sigma) b_{1p_1} a_{2p_2} \dots a_{np_n}$\\
        
            Аналогично доказывается для домножения на скаляр $\lambda$.
    `   \item  Пользуемся всё тем же определением, при $A^T$ у нас просто $a_{1p_1}$ превращается в $a_{p_1 1}$, но мы всё также получаем суммы по всем перестановкам. Нетрудно убедиться на примере, что мы получили действительно одно и то же.
        \item Иными словами перестановка двух строк определителя приводит к смене знака. Лучше смотреть док-во в лекции, но на самом деле всё по определению.
        \item Очевидно из линейности + кососимметричности: $f(A, \lambda A) = \lambda f(A, A) = -\lambda f(A, A) \Rightarrow f(A, A) = 0$
    \end{enumerate}
\end{theorembox}

\begin{remarkbox}
    \[
    \begin{vmatrix}
        A & B\\
        0 & C
    \end{vmatrix}
    = detA \cdot detC\]

    Потому что мы просто приводим A и C к треугольному виду как-то (мы точно знаем, что это возможно), а дальше просто берём произведение диагонали, а это и есть $detA \cdot detC$\\

    \[
    \begin{vmatrix}
        A & B\\
        С & 0
    \end{vmatrix}
    = (-1)^n
    \begin{vmatrix}
        B & A\\
        0 & C
    \end{vmatrix}
    = (-1)^n detB \cdot detC\]

    По аналогии, $(-1)^n$ возникает, потому что мы переставляем столбцы, а у нас det кососимметричен
\end{remarkbox}

\begin{theorembox}
    \[
    \begin{vmatrix}
        x_1 & x_2 & x_3\\
        y_1 & y_2 & y_3\\
        z_1 & z_2 & z_3
    \end{vmatrix}^2
    \leq (x_1^2 + y_1^2 + z_1^2)(x_2^2 + y_2^2 + z_2^2)(x_3^2 + y_3^2 + z_3^2)\]\\

    \textbf{Доказательство:}

    Доказывается геометрически, помним, что определитель - это по сути объём фигуры, натянутый на три вектора (вектора - это наши столбцы). Дальше просто оцениваем объём и возводим обе части неравенства в квадрат.
\end{theorembox}

\begin{definitionbox}
    \textbf{Алгебраическое дополнение} $A_{ij} = (-1)^{i + j} M_{ij}$, где $ M_{ij}$ - это минор матрицы, полученный вычёркиванием i-й строки и j-го столбца.
\end{definitionbox}

\begin{theorembox}
    Разложение по строке (столбцу): $detA = \sum_{i = 1}^n a_{ij} A_{ij}$\\

    \textbf{Доказательство:}
    
    См. лекция, там довольно тяжело. Начало примерно 1:10:00.
    
\end{theorembox}

\begin{theorembox}
    $A^{-1} = \frac{1}{detA} A^{ad}$, где $A^{ad}$ - матрица алгебраических дополнений.
\end{theorembox}


\end{document}
